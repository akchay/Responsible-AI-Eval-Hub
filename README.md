✨ **Responsible AI Guide** ✨

The future of AI is Responsible! This repository is a one-stop curated guide to high-quality research on developing and deploying responsible AI.

The 5 main pillars of Responsible AI are: 

1. Trustworthiness
2. Explainability
3. Safety and Security
4. Fairness and Bias
5. Privacy

| Date  | Paper | Key Takeway | Pillar |
| ------------- | ------------- | ------------- | ------------- |
| 3rd April 2024  | [Long-Form Factuality in Large Language Models](https://arxiv.org/pdf/2403.18802.pdf) | This paper proposes a novel evaluation method called Search-Augmented Factuality Evaluator (SAFE), which utilizes a search-enabled large language model to split a long-form response into individual facts, revise individual facts to be self-contained, determine the relevance of each individual fact to answering the prompt, and check the factuality of each relevant fact by issuing Google Search queries. |  Trustworthiness |

