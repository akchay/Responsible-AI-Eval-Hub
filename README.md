✨ **Responsible AI Evaluation Hub** ✨

The future of AI is Responsible! This repository is a one-stop shop for curated, high-quality research on the test and evaluation of responsible AI.

Responsible AI is a set of principles and practices that ensure AI is developed and used in a way that's beneficial, ethical, and minimizes risks. It's about building trust in AI by focusing on these core pillars:

1. Trustworthiness
2. Explainability
3. Safety and Security
4. Fairness and Bias
5. Privacy


**1. Trustworthiness** 

| Date  | Paper |
| ------------- | ------------- | 
| Apr 2024  | [Long-Form Factuality in Large Language Models](https://arxiv.org/pdf/2403.18802.pdf) | 


**2. Explainability**

| Date  | Paper | 
| ------------- | ------------- | 
| Sep 2021 | [Counterfactual Evaluation for Explainable AI](https://arxiv.org/pdf/2109.01962.pdf) | 
| Aug 2021 | [What Do You See?: Evaluation of Explainable Artificial Intelligence (XAI) Interpretability through Neural Backdoors](https://dl.acm.org/doi/abs/10.1145/3447548.3467213) | 
| May 2021 | [Better Metrics for Evaluating Explainable Artificial Intelligence](https://dl.acm.org/doi/abs/10.5555/3463952.3463962) | 
| Jan 2021 | [How can I choose an explainer? An Application-grounded Evaluation of Post-hoc Explanations](https://arxiv.org/pdf/2101.08758.pdf) | 
| Dec 2020 | [How can I explain this to you? an empirical study of deep neural network explanation methods](https://dl.acm.org/doi/10.5555/3495724.3496078) 
| May 2020 | [Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?](https://arxiv.org/abs/2005.01831) |
| Apr 2020 | [Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning](https://dl.acm.org/doi/10.1145/3313831.3376219) | 
| Jan 2020 | [Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making](https://dl.acm.org/doi/abs/10.1145/3351095.3372852) |  
| Jul 2019 | [Explainable AI in Industry](https://dl.acm.org/doi/10.1145/3292500.3332281) | 
| Mar 2019 | [The effects of example-based explanations in a machine learning interface](https://dl.acm.org/doi/10.1145/3301275.3302289) | 
| Feb 2018 | [Manipulating and Measuring Model Interpretability](https://arxiv.org/abs/1802.07810) | 
| Jan 2018 | [A Human-Grounded Evaluation Benchmark for Local Explanations of Machine Learning](https://arxiv.org/abs/1801.05075) | 


**3. Safety and Security**


**4. Fairness and Bias**


**5. Privacy**
